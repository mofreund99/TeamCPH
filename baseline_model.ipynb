{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    r2_score,\n",
    "),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "We use a **linear regression baseline** (ordinary least squares via `LinearRegression`) because it is transparent, fast to train, and easy to interpret. It also aligns with `MF_20251113.ipynb`, where a linear model is used with engineered calendar and lag features to explain daily revenue.\n",
    "\n",
    "For this baseline, the target is transformed with `log1p(Umsatz)` during fitting and transformed back with `expm1` for evaluation. This reduces skewness in revenue and improves stability while keeping the model linear in features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Following `MF_20251113.ipynb`, we use features that are available at day/product-group level and strongly related to demand:\n",
    "\n",
    "- **Calendar effects**: `IsWeekend`, `IsNewYears`, `IsHalloween`\n",
    "- **Seasonality (Fourier terms)**: `sin_1y`, `cos_1y`, `sin_2y`, `cos_2y`\n",
    "- **Event/holiday indicators**: `holiday`, `Easter`, `KielerWoche`\n",
    "- **Autoregressive signals**: `Revenue_lag1`, `Revenue_lag7` (within each `Warengruppe`)\n",
    "- **Product-group fixed effects**: one-hot encoded `Warengruppe` dummies\n",
    "\n",
    "These features provide a strong, interpretable baseline before moving to more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data (aligned with MF_20251113.ipynb)\n",
    "sales = pd.read_csv('/workspaces/TeamCPH/data/umsatzdaten_gekuerzt.csv', parse_dates=['Datum'])\n",
    "wetter = pd.read_csv('/workspaces/TeamCPH/data/wetter1.csv', parse_dates=['Datum'])\n",
    "kiwo = pd.read_csv('/workspaces/TeamCPH/data/kiwo.csv', parse_dates=['Datum'])\n",
    "holidays = pd.read_csv('/workspaces/TeamCPH/data/school_holidays_SH.csv', parse_dates=['Datum'])\n",
    "\n",
    "# Aggregate to daily revenue per product group\n",
    "sales_daily = (\n",
    "    sales\n",
    "    .groupby(['Datum', 'Warengruppe'], as_index=False)['Umsatz']\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "# Merge exogenous data\n",
    "merged = sales_daily.merge(wetter, on='Datum', how='left')\n",
    "merged = merged.merge(kiwo, on='Datum', how='left')\n",
    "merged = merged.merge(holidays, on='Datum', how='left')\n",
    "\n",
    "# Ensure expected indicator columns exist\n",
    "for col in ['holiday', 'Easter']:\n",
    "    if col not in merged.columns:\n",
    "        merged[col] = 0\n",
    "\n",
    "if 'KielerWoche' in merged.columns:\n",
    "    merged['KielerWoche'] = merged['KielerWoche'].fillna(0).astype(int)\n",
    "else:\n",
    "    merged['KielerWoche'] = 0\n",
    "\n",
    "# Calendar features\n",
    "merged = merged.sort_values(['Warengruppe', 'Datum']).reset_index(drop=True)\n",
    "merged['IsWeekend'] = merged['Datum'].dt.weekday.isin([5, 6]).astype(int)\n",
    "merged['IsNewYears'] = (merged['Datum'].dt.strftime('%m-%d') == '12-31').astype(int)\n",
    "halloween_days = [f'10-{day:02d}' for day in range(24, 32)]\n",
    "merged['IsHalloween'] = merged['Datum'].dt.strftime('%m-%d').isin(halloween_days).astype(int)\n",
    "\n",
    "# Seasonality features (Fourier terms)\n",
    "merged['DayOfYear'] = merged['Datum'].dt.dayofyear\n",
    "merged['sin_1y'] = np.sin(2 * np.pi * merged['DayOfYear'] / 365.25)\n",
    "merged['cos_1y'] = np.cos(2 * np.pi * merged['DayOfYear'] / 365.25)\n",
    "merged['sin_2y'] = np.sin(4 * np.pi * merged['DayOfYear'] / 365.25)\n",
    "merged['cos_2y'] = np.cos(4 * np.pi * merged['DayOfYear'] / 365.25)\n",
    "\n",
    "# Lag features within product group\n",
    "merged['Revenue_lag1'] = merged.groupby('Warengruppe')['Umsatz'].shift(1)\n",
    "merged['Revenue_lag7'] = merged.groupby('Warengruppe')['Umsatz'].shift(7)\n",
    "\n",
    "# Product-group dummies\n",
    "wg_dummies = pd.get_dummies(merged['Warengruppe'], prefix='WG', drop_first=True, dtype=int)\n",
    "merged = pd.concat([merged, wg_dummies], axis=1)\n",
    "\n",
    "# Define predictors\n",
    "predictors = [\n",
    "    'holiday', 'Easter', 'KielerWoche',\n",
    "    'IsWeekend', 'IsNewYears', 'IsHalloween',\n",
    "    'sin_1y', 'cos_1y', 'sin_2y', 'cos_2y',\n",
    "    'Revenue_lag1', 'Revenue_lag7',\n",
    "] + wg_dummies.columns.tolist()\n",
    "\n",
    "# Build modeling table and split\n",
    "model_df = merged[['Umsatz'] + predictors].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "X = model_df[predictors]\n",
    "y = np.log1p(model_df['Umsatz'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "print('Train shape:', X_train.shape)\n",
    "print('Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "We fit a **linear regression** model on `log1p(Umsatz)` using the engineered feature set above. This is the baseline benchmark for later, more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train baseline linear regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict in log-space and convert back to revenue space\n",
    "y_pred_log = model.predict(X_test)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "y_true = np.expm1(y_test)\n",
    "\n",
    "print('Baseline linear regression trained successfully.')\n",
    "print('Number of features:', X_train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "For the baseline linear regression, we report:\n",
    "\n",
    "- **MAE** (average absolute revenue error)\n",
    "- **RMSE** (penalizes larger errors)\n",
    "- **MAPE** (relative percentage error, easy to interpret across product groups)\n",
    "- **R² in log-space** (variance explained in the fitted target space)\n",
    "\n",
    "These metrics provide a clear benchmark for comparing later, more complex models (e.g., neural nets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the baseline model\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "r2_log = r2_score(y_test, y_pred_log)\n",
    "\n",
    "print(f'MAE (revenue):  {mae:,.2f}')\n",
    "print(f'RMSE (revenue): {rmse:,.2f}')\n",
    "print(f'MAPE (revenue): {mape:.2f}%')\n",
    "print(f'R² (log-space): {r2_log:.4f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
